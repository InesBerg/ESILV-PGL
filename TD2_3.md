## Exercise 1: Extract data from a website

### Exercise 1:.1 curl
```
curl https://opendomesday.org/api/1.0/county/
curl https://opendomesday.org/api/1.0/place/2346/
curl https://opendomesday.org/api/1.0/manor/181/

```
### Exercise 1:.2 curl and grep
```
curl https://opendomesday.org/api/1.0/county/ | grep -oP '(?<=href="/api/1.0/place/)[0-9]+(?=/")'

```
### Exercise 1:.3 curl, grep and for
```
mkdir derbyshire_places
for place_id in $(curl https://opendomesday.org/api/1.0/county/ | grep -oP '(?<=href="/api/1.0/place/)[0-9]+(?=/")'); do
  curl https://opendomesday.org/api/1.0/place/$place_id/ > derbyshire_places/place_$place_id.json
done

```
### Exercise 1:.4 curl, grep, for and sed
```
echo 'manor_id,geld,ploughs' > derbyshire_manors.csv
for place_id in $(ls derbyshire_places); do
  place_file="derbyshire_places/$place_id"
  for manor_id in $(grep -oP '(?<=href="/api/1.0/manor/)[0-9]+(?=/")' $place_file); do
    geld=$(grep -oP '(?<="geld": )\d+(?=,)' $place_file)
    ploughs=$(grep -oP '(?<="ploughs": )\d+' $place_file)
    echo "$manor_id,$geld,$ploughs" >> derbyshire_manors.csv
  done
done

```
### Exercise 1:.5 discover new commands
```
awk -F, 'NR>1 {sum+=$2} END {print sum}' derbyshire_manors.csv

```
### Exercise 1:.6 Bonus
```
#!/bin/bash

# Get place ids
place_ids=$(curl https://opendomesday.org/api/1.0/county/ | grep -oP '(?<=href="/api/1.0/place/)[0-9]+(?=/")')

# Download place details and manors
mkdir derbyshire_places
for place_id in $place_ids; do
  curl https://opendomesday.org/api/1.0/place/$place_id/ > derbyshire_places/place_$place_id.json
done

# Extract geld and ploughs data
echo 'manor_id,geld,ploughs' > derbyshire_manors.csv
for place_id in $(ls derbyshire_places); do
  place_file="derbyshire_places/$place_id"
  for manor_id in $(grep -oP '(?<=href="/api/1

```
